## 1. Introduction
Welcome to part one of Software Engineering Practices. Here, we will go over a few techniques that we can adopt as data scientists to be better developers and prepare for production level code. You will learn how to write clean and modular code, improve your code's efficiency, document effectively, and use version control. These are all essential skills to develop as a programmer and will really help you when implementing production solutions. In addition, data scientists often work side-by-side with software engineers, and it's important you work well together. This means being familiar with standard practices and being able to collaborate effectively with others on code. Let's walk through each of these practices and learn how they're applied as a data scientist.
## 2. Clean and Modular Code
The first practice we'll talk about, is writing code in a way that is clean and modular. Data scientists often struggle with this when they first start coding, or even if they've been coding for years in a more research or academic setting. When you're working in industry, your code could potentially be used in production. Production code just means code that is run on production servers. For example, when you're on your laptop using software products like Udacity, Google, or Amazon, the code that's running the service you're using is production code. Ideally, code that's being used in production should meet a number of criteria to ensure reliability and efficiency before it becomes public. For one, the code needs to be clean. Code is clean when it's readable, simple and concise. Here's an example in plain English of a sentence that is not clean. "One could observe that your shirt has been sullied, due to the orange color of your shirt that appears to be similar to the color of a certain kind of juice." This sentence is terribly redundant and convoluted. Just reading this makes me frustrated. This can be rewritten as, "It looks like you spilled orange juice on your shirt," and accomplish the same thing. But this sentence is much more concise and clear. Writing clean code is very important in an industry setting where on a team that's constantly iterating over its work. This makes it much easier for yourself and others to understand and reuse your code. In addition to being clean, your code should be modular. Meaning, your program is logically broken up into functions and modules. In programming, a module is just a python file. Similarly to how you can encapsulate code in a function and reuse it by calling the function in different places, you can encapsulate code within a module or file and reuse it by importing it in other files. We will see examples of this later. To you get a better understanding of what modular code is, try to think of it as putting your clothes away. Sure, you could just put all of your clothes in a single jar, but it wouldn't be very easy to find anything. Maybe because you can't ever find anything, you have multiple versions of the same shirt or socks because you repurchased them when you couldn't find them. It will be much better if instead, you had a drawer for tee-shirts, another one for just shirts, another for socks, and so on. With this design, if you need a nice outfit for an interview, you don't need to worry about buying one just because he couldn't find the right clothes. If you need to tell someone else how to find the right shirt, pants, and pair of socks, it will be much easier with this design. The same is true in writing modular code. Splitting a code into logical functions and modules, allows you to quickly find a relevant pieces of code. You can often generalize these pieces of code to be reused in different places, to prevent yourself from writing extra unnecessary lines of code. Abstracting out these details into these functions and modules can really help in improving the readability of your code. Again, programming in a way that makes it easier for a team to understand and iterate on is crucial for production. In this lesson, you will get practice writing code that is clean and modular to help you accomplish this.
## 3. Refactoring Code
When you first sit down to start writing code for a new idea or task, it's easy to pay little attention to writing good code and focus more on just getting it to work. So, your code typically gets a little messy and repetitive at this stage of development. This is okay. It's hard to know what's the best way to write your code before it's finished. For example, it could be difficult to know exactly what functions would best modularize the steps in your code if you haven't experimented enough with your code to understand what these steps are. That's why you should always go back to do some refactoring after you've achieved a working model. Code refactoring is a term for restructuring your code to improve its internal structure without changing its external functionality. Refactoring gives you an opportunity to clean and modularize your code after you've produced code that works. In the short-term, you might see this as a waste of time, since you could be moving on to the next feature. However, allocating time to refactoring your code really speeds up the time it will take you and your team to develop code in the long run. Refactoring your code consistently not only makes it much easier to come back to it later, it also allows you to reuse parts for different tasks and learn strong programming techniques along the way. The more you practice refactoring your code, the more intuitive it becomes. You'll start to find yourself writing more organized code on your first pass, with less to reorganize when you go back. Let's take a look at a couple of examples and get some practice.
## 4. Writing clean code
Now that you understand the importance of developing in a clean and modular way, let's break down what this means in code. The first tip for writing clean code, is to **use meaningful descriptive names for your variables and functions**. This can **help you explain most of your code without comments**. Take a look at this code that initializes a list of student test scores, prints the mean, curves each score by multiplying its square root by 10, and then prints the mean of the new curved scores. With this code, you wouldn't know what was happening right away without these comments. See how this compares to this cleaner code, which conveys the same purpose without the comments. Now, we know what both of these lists stand for without the comments, which will help us throughout the program wherever these variables are used. We also use the function with a descriptive name, mean, instead of running a calculation each time. This not only helps readability, but follows the DRY principle or don't repeat yourself that is important to writing modular code, which we'll talk more about later. In addition, we imported the math module to use its square root method instead of raising each score to 0.5 with double asterisks, which isn't only more readable, but also faster in Python 3. Try testing how effective your names are by asking a fellow programmer to guess the purpose of a function or variable based on its name without looking at your code. Coming up with meaningful names often requires effort to get right. Here are some guidelines. Let's start with the first guideline. **Be descriptive, and when appropriate, try implying the type** of whatever you're naming. Notice we call this list, age list instead of ages, which helps us avoid confusing the integer age and the list of ages later in this code. For Booleans, it's often helpful to prefix the name with words like is or as to make it clear that it's a condition. You can also use parts of speech to imply types by using verbs for functions and nouns for variables. Normally, you don't want to use abbreviations unless the word will be used many, many times, and you especially don't want single letter names. However, exceptions include names for counters such as i in this example, as well as common variable names using math like, x, y, t, and so on. Choosing when these exceptions can be made can be determined based on your audience for the code. If you work with other data scientists, certain variables may be common knowledge. While if you work with full-stack engineers, it might be necessary to provide more descriptive names in these cases as well. However, long names do not always mean meaningful names. You should be descriptive, but not with more characters than necessary. This first example is very verbose. This function computes the number of unique values in a list regardless of what that list is. So, we can generalize and remove of names list from the function name, and replace the argument name with arr, which is standard to represent an arbitrary array. In addition, implementation details are unnecessary to include in a function name. So, we can remove with set from the function name as well. The resulting function is much more clean and concise while still being descriptive. Another tip for writing clean code is to use whitespace properly. Code with poor or inconsistent spacing is the worst. Take a look at this mess. If you were handed this code as a developer, the first thing you should do is fix the whitespace and make it consistent. This is much nicer to read and work with. Organize your code with consistent indentation. The standard for Python is using four spaces for each indent, unlike we have here. Also, be sure to separate sections with blank lines to make it easier to organize and read. Lastly, try to limit your lines to around 79 characters. Seventy-nine is the guideline given in the PEP 8 Style Guide. In many good text editors, there's a setting to display a subtle line that indicates where the 79 character limit is. Notice how much clear it is to read this Mongo query in this code with shorter lines and proper indentation. Also, notice how much cleaner this ending part of the code is where we call create plot. For more guidelines on this, check out the code layout section of PEP 8 in the notes below.
## 5. Writing modular code
https://www.youtube.com/watch?v=qN6EOyNlSnk&t=311s  
If you recall from earlier in the lesson, writing Modular Code is a necessary practice in software development, where you split your program into logical functions and modules. Let's go over some guidelines to help you with this. First, Don't Repeat Yourself, modularization allows you to reuse parts of your code. Let's go back to the example earlier on grading test scores. Here, we have a list of test scores that we curve in three different ways, say you're an educator who gave out a test that was too difficult or gave a question that was a little unfair. So, you decide to figure out a way to boost your students' scores. For the first two methods, out of flat curve a 5 points to each score and 10 points to each score. In the third method, we apply a square root curve, where we find the square root of each score, and multiply it by 10. Right now, it's difficult to understand what this code is for and looks pretty repetitive. This is an example of spaghetti code, which is common in data scientists and is not something we want to follow. Let's use the tips we learned earlier on writing clean code and improve this with better naming and readable functions. We can represent this list of scores better with something descriptive, like test scores, and use numpy to get the mean of each list. We can also use list comprehensions to make this more concise and readable, and use more descriptive names for the score and resulting list, our code is clear now, but still needs more refactoring. First of all, these lines applying a flat curve of 5 and 10 look awfully similar. We can generalize this in one function and we can also consolidate all of these print statements into a four loop. This actually demonstrates the next tip, abstract that logic to improve readability. Notice how abstracting out code into a function not only makes it less repetitive, but also improves the readability with descriptive function names. You can easily guess that this line is applying a flat curve of 5 on the test scores list and that this line is doing the same thing with 10, and this line applies a different curve using square root and with this four loop not only are we removing repeated lines of code it's also easier to follow what's happening, we're clearly iterating through four lists and printing the mean of each. Note that although your code can become more readable when you abstract out logic into functions, it's possible to over-engineer this and have way too many functions. So, use your judgment, this leads us to the next tip. Minimize the number of entities like functions, classes, and modules. There are trade-offs to having function calls instead of in-line logic. If you've broken up your code into an unnecessary amount of functions and modules, you'll have to jump around everywhere. If you want to view the implementation details for something that may be too small to be worth it, it's kind of the same as naming variables. A longer variable name doesn't necessarily equate to increased readability, the same way creating more modules doesn't necessarily result in effective modularization. Moving on to the next tip, make sure that each function you write, is focused on doing one thing, for example you wouldn't want something like this, this is the same thing we had before except now each curve function also prints the mean in addition to returning the adjusted list. Avoid having unnecessary side effects and functions and keep them focused. Even if you rename them this way to indicate that they're printing the mean, the functions are still doing multiple things and become more difficult to generalize and reuse. Generally, if there's an and in your function name, consider refactoring. Another tip is that arbitrary variable names can be more effective in certain functions. Notice that in these functions, we broke some rules on using descriptive variable names. This is because arbitrary variable names in general functions such as this, can actually make the code more readable. Flat curve doesn't actually have to be for test scores, it can be used on any iterable that you want to curve up by a certain integer. While we're on the topic of writing simple and focused functions, another useful tip is to make sure that you use no more than three arguments when possible. Of course, this is not a hard rule and there are times it's more appropriate to use many parameters, but in the vast majority of cases, it's more effective to use fewer arguments. Remember, we are modularizing to simplify our code and make it more efficient to work with. If your function has a lot of parameters, you may want to rethink how you're splitting this up. With this small example, you saw how functions can be used to abstract out parts of a program to make it more readable, clear, and reusable. This becomes more essential, the more complex your algorithms are, especially in data science work.
## 6. Efficient code
When you refactor, it's important to improve the efficiency of your code in addition to making it clean and modular. There are two parts to make code efficient: reducing the time it takes to run, and reducing the amount of space it takes up the memory. Both can have a significant impact on a company or products performance. So, it's important to practice this. It's especially important if you will be working in a production environment. However, it should be noted that how important it is to improve efficiency is context dependent. Slow code, might be passible in one case and not another. For example, some batch data preparation processes, might not need to be optimized right away if it runs once every three days, for a few minutes. On the other hand, code used to generate posts to show on a social media feed needs to be relatively fast, since updates happen instantaneously. Again, you may spend a lot of time refactoring to clean or optimize your code after you already have something working. It's important to understand how valuable this is for your work and yourself as a developer. Each time you optimize your code, you'll pick up new knowledge and skills which will make you a more efficient programmer over time. Let's see a few examples of inefficient code, and practice refactoring to optimize their performance.

Let's go through an example scenario where we optimize some code to be more efficient. Say we're managing books for a store and we want to find all the books published within the last two years about code. We have a file that lists all the IDs of books published in the last two years, called the books published last two years.txt. As well as a file for all Coding books, all_coding_books.txt. Since we want to find all the coding books published within the last two years, we'd want to find the book IDs included in both of these files. Your coworker came up with one approach and shows you this code to find the books and both files. After reading in the files, their strategy is to loop through each book in the first file, check if it's contained in the second file, and if so, add it to the final list. This makes sense and is an intuitive first approach. Let's see how long it takes to run. So that took about 13.6 seconds. There are several things we can do to make this more efficient. Here's some tips. First, use vector operations over loops when possible. Numpy and Pandas are your best friends for this. There are many cases in which you can replace loops with NumPy and Pandas functions that use vector operations to make your computations a lot faster. Sometimes there's a method that does exactly what you need. Other times, you need to be a little creative. This example in particular has a useful method you can use. Let me show you how I would approach this. No joke, I google. How to find common elements in two NumPy arrays, and here are the results I get. Used NumPy's intersect 1d method to get the intersection of the recent books including books arrays. I'll give you the same notebook and I'll put a cell right here with code to record the time it takes to run. Write your line of code in this line. The second tip is to know your data structures and which methods are faster. In addition to relying on Numpy and Pandas, it's often good to double-check whether there is a data structure or method in Python that you can use to accomplish your task more effectively. For example, in this case, do you recall a data structure in Python that stores a group of unique elements and can quickly compute intersections and unions of different groups? Sets. You can read more about why sets are more efficient than lists for this task in the link at the bottom of this page. Also, remember how I said I Googled everything? Last time, I was Googling how to find common elements in specifically Numpy arrays. But you can go even more general and Google something like, how to find common elements into lists Python and you'll see posts like this that share and compare different answers. You can see the set being introduced here. This seems to have a lot of votes but ultimately, we should try different methods and compare their efficiency for our example. Because different methods perform differently in different contexts, it's smart to always test for yourself. In the next cell of the Jupyter notebook, find out how long it takes to compute the common elements of recent books and coding books using the Python sets intersection method.

## 7. Documentation
Documentation is additional text or illustrated information that comes with, or is embedded in, the code of software. Documentation is helpful for clarifying complex parts of your program, making your code easy for yourself and others to navigate and quickly conveying how and why different components of your program are used. There are several types of documentation you can add at different levels of your program. First, you can add documentation at the line level using in-line comments to clarify your code. Second, you can add documentation at the function or module level using docstrings to describe its purpose and details. Finally, you can add documentation at the project level using various tools such as a readme file to document details about the project as a whole and how all the files work together. In the next few sections, we will practice using these different modes of documentation and learn best practices to make sure our documentation is effective and useful.
## 8. In-line comments
 The first mode of documentation we'll talk about are in-line comments. By now, you've probably seen this many times, texts following a hash symbol throughout your code. They're used to explain parts of your code and really help future contributors understand your work. There are different ways comments are used and definitely differences among great comments, okay comments, and even users' comments. One way comments are used is to document the major steps of complex code to help readers follow. For example, with the guiding comments in this function, you don't really need to understand the code to follow what this function does. If I was seeing this for the first time and I had no idea what these functions or tools were, these comments really help me understand the purpose of each block of code, and even help me figure out individual lines of code or methods. However, others would argue that this is using comments to justify bad code, and that if code requires comments to follow, it's a sign refactoring is needed. Comments are valuable for explaining where code cannot. For example, the history behind why a certain method was implemented in a specific way. Sometimes an unconventional or seemingly arbitrary approach may be used because of some obscure external variable causing side effects. These things are difficult to explain with code. These numbers for detecting edge levels in an image may seem arbitrary, but the programmer experimented with different numbers and realized that this was the one that worked for this specific use case.
## 9. Docstrings
Docstrings or documentation strings are valuable pieces of documentation that explain the functionality of any function or module in your code. Ideally, all of your functions should have docstrings. Here's a function for population density. A docstring is always surrounded by triple quotes. If you feel that this one line of documentation is sufficient for you to end the docstring at this point, single line docstrings are perfectly acceptable. If however, you think that the function is complicated enough to warrant a longer description, you can add a more thorough paragraph after the one line summary. The next element of a docstring is an explanation of the function's arguments. Here, you list the arguments, state their purpose, and state what types the arguments should be. Finally, it's common to provide some description of the output of the function. Every piece of the docstring is optional. However, docstrings are part of good coding practice. They assist you and future users of your code in understanding the code you produce. You can read a more thorough explanation of docstring conventions in the link below.
## 10. Version Control
To familiarize yourself with how you may use version control at work, we'll first take a look at an example scenario where you are data scientists using Git at work. We'll practice the commands to use in these type of scenarios, and then we'll go over some of the unique challenges and techniques for versioning data science work.
### Scenario #1
https://www.youtube.com/watch?v=C92YcuwjZOs&t=16s
Imagine you're part of a data science team that's responsible for building a company's recommendation engine. You're sitting at your desk working on a feature that incorporates demographic data like age, gender, and relationship status to improve recommendations to users. You're midway through this implementation when your boss comes over to notify you that the business intelligence team predicts that a user's friend groups will produce the best recommendations in the short-term and wanted to prioritize this immediately. Looking at the recommendation engine code you have on your screen, you can see there's a bunch of unfinished non-working code that you've added while working on the demographic feature. Running this code right now would break. If you want to get started on this new friend groups feature now, you'd have to undo all of this work maybe by editing back lines you've modified and committing out lines of code you added. This would be a very messy and risky route, or say you're using a version control system like Git. You can simply commit your changes and create another branch for this new feature. Here's what I mean. Your company has a Git repository for its recommendation engine and has a master branch, which holds the code used in production and the develop branch which holds the latest stable version of code with changes for the next release. You have a local version of this repository on your laptop, and to get the latest stable version you pull from the develop branch. When you start working on this demographic feature, you create a new branch for this called "Demographic" and start working on your code in this branch. However, in the middle of your work, you need to work on another feature. So, you commit your changes on this demographic branch and switch back to the develop branch. From the stable develop branch, you create another branch for a new feature called friend groups. After you finish your work on the friend groups branch, you commit your changes, switch back to development branch, merge it with the friend groups branch, and push this to the remote repository's develop branch. Now, you can switch back to the demographic branch to continue your progress on that feature. As you can see here, proper use of Git commits and branches can help you work on multiple features at once and switch between them with ease.

Let's walk through the Git commands that go along with each step in the scenario you just observed in the video.

Step 1: You have a local version of this repository on your laptop, and to get the latest stable version, you pull from the develop branch.
```
# Switch to the develop branch
git checkout develop

# Pull the latest changes in the develop branch
git pull
```
Step 2: When you start working on this demographic feature, you create a new branch called demographic, and start working on your code in this branch.
```
# Create and switch to a new branch called demographic from the develop branch
git checkout -b demographic

# Work on this new feature and commit as you go
git commit -m 'added gender recommendations'
git commit -m 'added location specific recommendations'
```

Step 3: However, in the middle of your work, you need to work on another feature. So you commit your changes on this demographic branch, and switch back to the develop branch.
```
# Commit your changes before switching
git commit -m 'refactored demographic gender and location recommendations '

# Switch to the develop branch
git checkout develop
```
Step 4: From this stable develop branch, you create another branch for a new feature called friend_groups.
```
# Create and switch to a new branch called friend_groups from the develop branch
git checkout -b friend_groups
```
Step 5: After you finish your work on the friend_groups branch, you commit your changes, switch back to the development branch, merge it back to the develop branch, and push this to the remote repository’s develop branch.
```
# Commit your changes before switching
git commit -m 'finalized friend_groups recommendations '

# Switch to the develop branch
git checkout develop

# Merge the friend_groups branch into the develop branch
git merge --no-ff friends_groups

# Push to the remote repository
git push origin develop
```
Step 6: Now, you can switch back to the demographic branch to continue your progress on that feature.
```
# Switch to the demographic branch
git checkout demographic
```
### Scenario #2
https://www.youtube.com/watch?v=w1iHWpwOkMg&t=79s
After working on this recommendation feature for a while, you've created a model to produce recommendations based on friend groups. The model is scored pretty well on your validation set, but you remember it did even better just a few hours ago. You've been experimenting with tweaks to this model, and you're not sure what combination of parameters and tweaks were in place when your model scored the highest. Luckily, you've been including a message with each commit noting what you did as well as the training and cross-validation scores for each commit. Instead of spending a bunch of time trying to retrace your steps from memory or testing a bunch of tweaks again to try and get the same score, you can check your commit history seeing messages of the changes you need and how well it performed. The model at this commit seem to be scoring the highest, so you decide to take a look. After inspecting your code, you've realized what modifications made this perform well and use those for your model. Now, you're pretty confident merging this back to the develop branch and pushing the updated recommendation engine.
Let's walk through the Git commands that go along with each step in the scenario you just observed in the video.

Step 1: You check your commit history, seeing messages about the changes you made and how well the code performed.
```
# View the log history
git log
```
Step 2: The model at this commit seemed to score the highest, so you decide to take a look.
```
# Check out a commit
git checkout bc90f2cbc9dc4e802b46e7a153aa106dc9a88560
```
After inspecting your code, you realize what modifications made it perform well, and use those for your model.

Step 3: Now, you're confident merging your changes back into the development branch and pushing the updated recommendation engine.
```
# Switch to the develop branch
git checkout develop

# Merge the friend_groups branch into the develop branch
git merge --no-ff friend_groups

# Push your changes to the remote repository
git push origin develop
```
### Scenario #3
https://www.youtube.com/watch?v=36DOnNzvT4A
While you were working on these changes, your co-worker, Andrew, has been working on improvements to the documentation of the same recommendation engine on a different branch called Documentation. Andrew commits his changes to the documentation branch, switches to the development branch and pulls down the latest changes from the remote repository on this branch, which includes the change I previously merged for the friend groups feature. Then, Andrew merges his documentation branch to the develop branch on his local repository, and then pushes his changes up to update the develop branch on the remote repository. After the team reviewed both of your work, they merged update from the develop branch to the master branch. Now, they pushed the changes to the master branch on the remote repository. These changes are now in production. Using branches, commit messages, and merging demonstrate just a few ways version control can be used in data science on a team, but the process will vary based on your team.

Let's walk through the Git commands that go along with each step in the scenario you just observed in the video.

Step 1: Andrew commits his changes to the documentation branch, switches to the development branch, and pulls down the latest changes from the cloud on this development branch, including the change I merged previously for the friends group feature.
```
# Commit the changes on the documentation branch
git commit -m "standardized all docstrings in process.py"

# Switch to the develop branch
git checkout develop

# Pull the latest changes on the develop branch down
git pull
```
Step 2: Andrew merges his documentation branch into the develop branch on his local repository, and then pushes his changes up to update the develop branch on the remote repository.
```
# Merge the documentation branch into the develop branch
git merge --no-ff documentation

# Push the changes up to the remote repository
git push origin develop
```
Step 3: After the team reviews your work and Andrew's work, they merge the updates from the development branch into the master branch. Then, they push the changes to the master branch on the remote repository. These changes are now in production.
```
# Merge the develop branch into the master branch
git merge --no-ff develop

# Push the changes up to the remote repository
git push origin master
```
